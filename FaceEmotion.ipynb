{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "372e0af1-006a-4608-945c-527b6205b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b70e8c-0f67-4fed-bdd5-ab94be5c8cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'images/train'\n",
    "TEST_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b65a15c0-1426-41b0-9c50-b8386740b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createdataframe(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir, label)):\n",
    "            image_paths.append(os.path.join(dir, label, imagename))\n",
    "            labels.append(label)\n",
    "        print(label, \"completed\")\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "108e4e1e-cf5f-49f4-943b-03126aa2a2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n",
      "                                image     label\n",
      "0            images/train\\angry\\0.jpg     angry\n",
      "1            images/train\\angry\\1.jpg     angry\n",
      "2           images/train\\angry\\10.jpg     angry\n",
      "3        images/train\\angry\\10002.jpg     angry\n",
      "4        images/train\\angry\\10016.jpg     angry\n",
      "...                               ...       ...\n",
      "28816  images/train\\surprise\\9969.jpg  surprise\n",
      "28817  images/train\\surprise\\9985.jpg  surprise\n",
      "28818  images/train\\surprise\\9990.jpg  surprise\n",
      "28819  images/train\\surprise\\9992.jpg  surprise\n",
      "28820  images/train\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createdataframe(TRAIN_DIR)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0c31b01-6eb9-4671-a545-c4c248ecd964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n",
      "                               image     label\n",
      "0            images/test\\angry\\0.jpg     angry\n",
      "1            images/test\\angry\\1.jpg     angry\n",
      "2           images/test\\angry\\10.jpg     angry\n",
      "3        images/test\\angry\\10002.jpg     angry\n",
      "4        images/test\\angry\\10016.jpg     angry\n",
      "...                              ...       ...\n",
      "28816  images/test\\surprise\\9969.jpg  surprise\n",
      "28817  images/test\\surprise\\9985.jpg  surprise\n",
      "28818  images/test\\surprise\\9990.jpg  surprise\n",
      "28819  images/test\\surprise\\9992.jpg  surprise\n",
      "28820  images/test\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createdataframe(TEST_DIR)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0051842e-de16-4fea-9778-317e7af1c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, grayscale=True)\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c0d5128-d7dc-44d0-bf70-e7de418aab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c0c50f1-e68c-479f-963b-b26280fc38c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64443c38d212461ab17a1bf303bb7517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6299eee79cd0483c9a8011c068dc7d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])\n",
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d69c1871-6b68-4946-9109-135c61f44773",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features / 255.0\n",
    "x_test = test_features / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "231cd284-44c6-4e48-b592-844b483cbc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(train['label'])\n",
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])\n",
    "y_train = to_categorical(y_train, num_classes=7)\n",
    "y_test = to_categorical(y_test, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ce80b36-8b6c-4427-82f5-149c9dd58d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# model compilation\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca4ab03-384a-47cb-8944-06c163827caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "226/226 [==============================] - 1362s 6s/step - loss: 1.8054 - accuracy: 0.2503 - val_loss: 1.7824 - val_accuracy: 0.2611\n",
      "Epoch 2/100\n",
      "226/226 [==============================] - 2120s 9s/step - loss: 1.7536 - accuracy: 0.2735 - val_loss: 1.6638 - val_accuracy: 0.3346\n",
      "Epoch 3/100\n",
      "226/226 [==============================] - 6306s 28s/step - loss: 1.6237 - accuracy: 0.3537 - val_loss: 1.4627 - val_accuracy: 0.4279\n",
      "Epoch 4/100\n",
      "226/226 [==============================] - 1801s 8s/step - loss: 1.5077 - accuracy: 0.4130 - val_loss: 1.3678 - val_accuracy: 0.4684\n",
      "Epoch 5/100\n",
      "226/226 [==============================] - 76508s 340s/step - loss: 1.4471 - accuracy: 0.4397 - val_loss: 1.2898 - val_accuracy: 0.5048\n",
      "Epoch 6/100\n",
      "226/226 [==============================] - 1008s 4s/step - loss: 1.4045 - accuracy: 0.4605 - val_loss: 1.2730 - val_accuracy: 0.5141\n",
      "Epoch 7/100\n",
      "226/226 [==============================] - 985s 4s/step - loss: 1.3678 - accuracy: 0.4700 - val_loss: 1.2206 - val_accuracy: 0.5353\n",
      "Epoch 8/100\n",
      "226/226 [==============================] - 977s 4s/step - loss: 1.3409 - accuracy: 0.4872 - val_loss: 1.1851 - val_accuracy: 0.5461\n",
      "Epoch 9/100\n",
      "226/226 [==============================] - 1220s 5s/step - loss: 1.3188 - accuracy: 0.4952 - val_loss: 1.1489 - val_accuracy: 0.5641\n",
      "Epoch 10/100\n",
      "226/226 [==============================] - 2034s 9s/step - loss: 1.3000 - accuracy: 0.5042 - val_loss: 1.1294 - val_accuracy: 0.5697\n",
      "Epoch 11/100\n",
      "226/226 [==============================] - 3432s 15s/step - loss: 1.2778 - accuracy: 0.5101 - val_loss: 1.1473 - val_accuracy: 0.5688\n",
      "Epoch 12/100\n",
      " 69/226 [========>.....................] - ETA: 9:00 - loss: 1.2604 - accuracy: 0.5181"
     ]
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ea3999-7adb-46e2-bb23-800513018cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\", 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3495d73c-a6ed-4ab2-9dd9-e589b6d476b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
